# å¯¼å…¥osæ¨¡å—ï¼Œç”¨æ¥å¤„ç†ç¯å¢ƒå˜é‡
import os

# --- å…³é”®ä¿®æ­£ï¼šåœ¨æ‰€æœ‰ä»£ç è¿è¡Œå‰ï¼Œæ¸…é™¤ä»£ç†è®¾ç½® ---
# è¿™å‡ è¡Œä»£ç ä¼šå‘Šè¯‰æœ¬æ¬¡è¿è¡Œçš„ç¨‹åºï¼Œå¿½ç•¥ç³»ç»Ÿä¸­çš„æ‰€æœ‰ä»£ç†è®¾ç½®
os.environ['HTTP_PROXY'] = ''
os.environ['HTTPS_PROXY'] = ''
os.environ['http_proxy'] = ''
os.environ['https_proxy'] = ''
# --- ä¿®æ­£ç»“æŸ ---

from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from apple_scraper.fetch_links import get_top_app_urls
from apple_scraper.fetch_details import get_app_details
from apple_scraper.utils import save_to_csv

MAX_APPS_PER_CATEGORY = 100

def run(category_name, category_id):
    print(f"ğŸ“¥ æ­£åœ¨æŠ“å–ã€{category_name}ã€‘ç±»åˆ«ï¼ˆID: {category_id}ï¼‰ï¼Œç›®æ ‡æ•°é‡: {MAX_APPS_PER_CATEGORY}...")
    
    driver = None # å…ˆå£°æ˜driverå˜é‡
    try:
        # è¿™é‡Œçš„ä»£ç å’Œä¹‹å‰ä¸€æ ·
        driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))
        
        urls = get_top_app_urls(driver, category_name, category_id, max_apps=MAX_APPS_PER_CATEGORY)
        
        if not urls:
            print(f"ğŸŸ¡ æœªèƒ½ä¸ºã€{category_name}ã€‘è·å–åˆ°ä»»ä½•Appé“¾æ¥ï¼Œè·³è¿‡åç»­æ­¥éª¤ã€‚")
            return

        all_app_data = []
        for url in urls:
            details = get_app_details(url) 
            if details:
                details['category'] = category_name
                details['url'] = url
                all_app_data.append(details)
        
        if all_app_data:
            save_to_csv(all_app_data, category_name)
        else:
            print(f"ğŸŸ¡ ã€{category_name}ã€‘çš„Appè¯¦æƒ…å‡æŠ“å–å¤±è´¥ã€‚")
            
    except Exception as e:
        print(f"âŒ åœ¨å¤„ç†ã€{category_name}ã€‘æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
    finally:
        # ç¡®ä¿æµè§ˆå™¨æœ€åè¢«å…³é—­
        if driver:
            driver.quit()

if __name__ == "__main__":
    categories_to_scrape = {
        "å¨±ä¹": "6016",
        "è´¢åŠ¡": "6015",
        "æ•™è‚²": "6017",
        "éŸ³ä¹": "6011",
        "æ¸¸æˆ": "6014",   
        "å·¥å…·": "6002",
        "æ‘„å½±ä¸å½•åƒ": "6008",
        "å¥åº·å¥ç¾": "6013",
        "ç”Ÿæ´»": "6012",
        "ç¤¾äº¤": "6005",
        "è´­ç‰©": "6024",
        "æ—…æ¸¸": "6003",
        "ç¾é£Ÿä½³é¥®": "6023",
        "ä½“è‚²": "6004",
        "æ–°é—»": "6009",
        "å‚è€ƒ": "6006",
        "åŒ»ç–—": "6020",
        "å¯¼èˆª": "6010",
        "å•†åŠ¡": "6000",
        "å›¾ä¹¦": "6018",
        "å¤©æ°”": "6001",
        "æŠ¥åˆŠæ‚å¿—": "6021",
        "å„¿ç«¥": "6019",
        "æ•ˆç‡": "6007",
        "è´´çº¸": "6025"
    }
    
    for name, cid in categories_to_scrape.items():
        run(name, cid)
        print("-" * 40)